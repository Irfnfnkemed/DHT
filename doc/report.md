# Report

## **RPC**
* **`rpc/rpc.go`**:
实现了用户池(client pool)。当节点试图与其他节点联系时，如果相应的pool内没有可用连接，便建立多个连接，存入用户池中。之后每次联系时，只需从用户池中取出可用连接，当联系结束后归还连接。这样避免运行时每次远端调用都重新建立连接，节约了大量时间。

### 一些细节与想法
* 如果相应的pool内没有可用连接，需要建立多个连接存入池中(`CreatClientPool`)。这个数量的选取需要反复试验。过少，不足以满足节点之间的多线程通讯要求，容易超时(等待连接归还时间过长)；过多，那么耗时过长，造成资源浪费。
* `RemoteCall`需要加入时限。除了一些网络问题之外，一个严重的问题是节点调用 `RemoteCall`可能是嵌套的，一旦连接池中可用连接耗尽，就可能造成死锁(如A调用`RemoteCall`，在某些特殊情况下调用对象可能是自身，这意味着A将再次调用`RemoteCall`。然而如果此时只剩一个可用连接，那么第二次调用将等待连接，而第一次调用等待第二次调用完成，造成死锁)。
* 用户池限制了节点间多线程交流的数量，一旦程序运行所需的线程数量远超过用户池承载能力的上限，就会造成严重的竞争和延迟。实际上，相较于每次远端调用都建立新连接(无线程数上限)，用户池更贴近真实情况下的服务器沟通情况，更有利于测试程序给服务器带来的压力大小。


## **Chord**
### 文件结构
* **`chord/chord.go`**:
实现chord的主体部分，包括节点的插入、退出，数据的插入、查找、删除，以及环结构的维护。
* **`chord/data.go`**:
维护chord的数据存储模式，有overwrite模式(用于测试)和append模式(用于chat)。
* **`chord/rpcWrapper.go`**:
包裹`chord.go`中需要用到的远端调用的函数，便于注册服务和控制。
* **`chord/tool.go`**:
包括了一些辅助方法。

### 一些细节与想法
* 由于用户池的建立需要一定的时间，因此在调用`Run`后，需要阻塞节点的 `Create`或`Join`，防止因连接未建立完毕而产生死锁。另外，对于一个`*rpc.Client`对象，其与`*rpc.Server`的连接只需`Accept`一次，同时为了防止资源泄漏，应该保留所有用于建立连接的`conn`对象，在结束时释放。
* 判定某地址是否属于目标区间时，若目标区间的上下界重合，则由于环结构，应该认为地址是否属于目标区间（除非区间两端开，且目标恰与区间上下界重合），否则找前驱时会造成死循环。
* `Quit`函数需要更改前驱后继的环指向，并转移数据。为了防止在更改转移过程中，`Stabilize`对过程造成不可控的影响(如后继在更新前驱之前，发现原前驱下线，认为其异常退出，执行数据恢复；如当前节点进行`Stabilize`导致环结构被错误改回)，需要在操作前阻塞当前、前驱、后继的`Stabilize`进程，待环结构重构后再重新解除阻塞。另外，需要特判前驱后继是否相同、是否是自己，防止死锁。
* `Stabilize`时，若发现后继是自己，也需要更改后继，否则会死循环。这主要是针对环结构初步形成时(如刚加入第二个节点)的情况。
* `Stabilize`的频率需要反复测试，若频率过低，则修复能力过弱；若太高，则容易与其他函数发生纠缠。
* `FixFinger`时，若发现路由表指向的对象已下线，则更改其为上线的节点，防止死循环。
* 数据的转移的原因有三：`Join`，`Quit`，`ForceQuit`。对于加入，在`Stablize`更改后继时转移数据；对于正常退出，直接在进程中完成转移；对于异常退出，在`Stablize`中，后继尝试得到前驱时，检测到前驱下线，便利用备份进程数据恢复。


## **Kademlia**
### 文件结构
* **`kademlia/kademlia.go`**:
实现kademlia的主体部分，包括节点的插入、退出，数据的插入、查找、删除，以及结构的维护。
* **`kademlia/bucket.go`**:
实现kademlia中的桶结构，包括对桶的各种操作和维护。
* **`kademlia/data.go`**:
维护kademlia的数据，包括重新发布时间与丢弃时间。
* **`kademlia/rpcWrapper.go`**:
包裹`chord.go`中需要用到的远端调用的函数，便于注册服务和控制。
* **`kademlia/tool.go`**:
包括了一些辅助方法，以及`NodeLookup`,`Get`中所使用的类似于`std::set`的结构。

### 一些细节与想法
* 桶、`tool.Order`(用于`NodeLookup`,`Get`)中的元素均为有序排列，且大量涉及插入、删除、移动操作，因此选用链表来作为实现结构。
* 由于Kademlia涉及大量对同一节点的桶的同时操作，故对桶的上锁需要格外谨慎。另外，需要注意在同一函数中，两次上锁解锁之间，由于并发运行，因此先前拿出的临时变量可能并不代表此时真实的值，这意味着需要相应地做出错误判断与处理。
* 在`Ping`成功之后，不应该对发起端和被调用端的桶进行更新。因为在发现新的沟通后，节点会试图将其加入桶，而当桶已经满时，节点会尝试`Ping`桶中最不常联系的节点。因此，若在`Ping`成功之后，发起端和被调用端的桶进行更新，更新的过程又可能会调用`Ping`，然后再次试图更新，如此往复，造成死循环。
* Kademlia中有大量可以并发执行的操作，比如`Republish`时可以一定程度上并发地对所有相应的数据进行重发、`Put`时确定数据存储的目标节点后，可以一定程度上并发地向各节点发送存储请求。这样可以提高效率。
* `Republish`、`NodeLookup`等的执行过程中，不应同时对所有的目标进行并发操作(容易造成严重的竞争)，一种比较好的方法是设置间隔时间(如25ms)，如果到了间隔时间上一操作还未完成，再进行并发操作。这样使得操作有一定的错位，又保证了一定的效率(每一条操作最多多等待一个时间间隔)。
* 重新发布时间、舍弃时间、`maintain`中的相关检测周期的时间都需要反复测试。否则，可能发生数据未及时转移、数据被异常舍弃、与`Put`、`Get`等发生严重竞争等错误情况。

## **Chat**
* **`chat/chat.go`**:
实现chat的内部逻辑，包括对chord协议节点的包装与拓展、聊天节点的操作等。
* **`chat/interactive.go`**:
实现控制台与用户之间的交互。
* **`chat/rpcWrapper.go`**:
包裹`chat.go`中需要用到的远端调用的函数(二次包装)，便于注册服务和控制。
* **`chat/tool.go`**:
包括了一些辅助方法，如输入、居中打印、json格式转换与逆转换等。